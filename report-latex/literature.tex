\subsection{Self-supervised learning}

Ранние работы, развивающие парадигму self-supervised learning, предлагают некоторые искусственные задачи для обучения нейронной сети. Такие задачи должны быть достаточно сложными, чтобы нейронная сеть извлекала семантические признаки изображений, полезные для других задач обучения с учителем. Примерами подобных задач являются колоризация изображений (предсказание цветовых каналов ab по каналу светлоты L в цветовом пространстве CEI Lab) \cite{colorization}, решение пазла из фрагментов изображения \cite{jigsaw}, предсказание угла поворота изображения \cite{rotation}. На момент своего появления данные методы показывали наилучшее качество на ряде контрольных задач среди других алгоритмов предобучения без учителя. Однако все эти методы значительно уступали предобучению на классификацию набора данных ImageNet \cite{imagenet}.

Настоящим прорывом в сфере self-supervised learning можно считать 2020 год, когда появились методы, не уступающие предобучению на наборе данных ImageNet. Данные алгоритмы обучения основаны на использовании так называемой контрастной функции потерь (англ. contrastive loss) \cite{contrastive}. Идея в том, что для каждого изображения создается несколько версий (например, с помощью применения аугментаций), которые служат позитивными примерами. В свою очередь, версии других изображений являются негативными примерами. При обучении с контрастной функцией потерь нейронная сеть должна ''сближать'' представления позитивных примеров и ''расталкивать'' представления негативных примеров. По описанной схеме работает алгоритм \textit{SimCLR} (англ. A Simple Framework for Contrastive Learning of Visual Representations) \cite{simclr}: в качестве двух версий изображения используются две случайные аугментации, которые пропускаются через одну и ту же нейронную сеть-кодировщик (более подробное описание алгоритма доступно в \hyperref[simclr:1]{разделе 3}).

Другой метод, \textit{MoCo} (англ. Momentum Contrast) \cite{moco}, также использует контрастную функцию потерь, однако представления позитивных и негативных примеров формируются по-другому. В алгоритме SimCLR две аугментированные версии изображения используются симметрично. Метод MoCo, наоборот, обрабатывает две версии изображения по-разному: одна условно называется \textit{запросом} (англ. query), другая \textit{ключом} (англ. key). Нейронная сеть-кодировщик для запросов обучается методом обратного распространения ошибки. Напротив, веса кодировщика для ключей обновляются с помощью экспоненциального сглаживания с весами кодировщика для запросов (так называемый \textit{инерциальный кодировщик}, англ. momentum encoder). В описанном алгоритме градиент не пропускается через представления ключей, а значит, отпадает необходимость сохранять графы вычислений кодировщика ключей для метода обратного распространения ошибки. Данный трюк позволяет увеличить число негативных ключей, используемых при одном обновлении кодировщиков, что позитивно сказывается на итоговом качестве модели.

Существуют работы, проводящие сравнительный анализ обучения в парадигме self-supervised learning и обучения с учителем. В статье \cite{dilo} показано, что нейронные сети, обученные методами self-supervised learning, плохо справляются с выделением переднего и заднего плана на изображениях (в отличие от нейронных сетей, обученных на классификацию изображений). Вдохновившись этим наблюдением, авторы предложили новый тип аугментаций, основанный на изменении фона изображения. Они использовали вспомогательный алгоритм для выделения переднего и заднего плана изображения, после чего передний план вставлялся поверх другого изображения, которое и использовалось в качестве фона. Включение аугментаций такого типа в обучение позволило моделям лучше различать передний и задний план изображений, что привело к улучшению качества на контрольных задачах.

Кроме того, некоторые ранние методы предобучения без учителя используют суррогатную разметку для обучения. В исследовании \cite{surrogate} авторы предлагают брать каждое изображение обучающей выборки как отдельный класс. При этом различные аугментации изображения являются примерами данного класса. Авторы показывают, что обученные описанным способом представления, во-первых, являются инвариантными относительно использованных аугментаций, а во-вторых, неплохо справляются с контрольными задачами классификации различных наборов данных. Последнее соображение устанавливает связь между контрастными self-supervised learning алгоритмами и методами с суррогатной классификацией.

\subsection{Обучение со случайной разметкой}

Предыдущие работы показывают, что нейронные сети с достаточно большим количеством парамеров легко выучивают данные со случайной разметкой по классам \cite{randlabels}. Представления, которые получаются у подобных моделей, оказываются практически бесполезными для использования на других задачах, поскольку разметка обучающей выборки никак не соотносится с разметкой тестовой выборки. Тем не менее, на сегодняшний день не до конца ясно, что именно выучивают нейронные сети при данной постановке. В одном из недавних исследований \cite{randlabels2} упоминается следующий феномен: нейронные сети, обученные на классификацию случайной разметки, дообучаются на другие задачи быстрее, чем при случайной инициализации. Таким образом, случайную разметку можно использовать для предобучения нейронных сетей \cite{randlabels3}, что позволяет проводить параллели с обучением в парадигме self-supervised learning (хотя, разумеется, нейросетевые представления, полученные при обучении со случайной разметкой куда хуже переносятся на другие задачи). Наши эксперименты дополняют предыдущие исследования и демонстрируют, что две описанные постановки имеют схожую динамику обучения.

\subsection{Эффекты обобщения и запоминания}

Обучение на случайной разметке тесно связано с понятиями обобщения и  запоминания нейронной сети. Поскольку при случайной разметке нет никакой корреляции между изображениями и целевой переменной, то для достижения идеального качества на обучаюшей выборке от нейронной сети требуется запомнить все обучающие примеры. Исследования обобщающей способности и запоминания в нейронных сетях являются крайне актуальными в современном глубинном обучении.

Одна из ранних работ по данной теме показывает, что при обучении с учителем (классификации изображений) некоторые обучающие объекты правильно классифицируются нейронной сетью значительно чаще, чем другие \cite{memorization}. Авторы предполагают, что в контексте каждой задачи существуют простые и сложные объекты, и нейронные сети предпочитают выучивать легкие объекты раньше, чем тяжелые. Данную стадию обучения принято называть \textit{обобщением} (англ. generalization), её отличает выучивание закономерностей в обучающей выборке, а не конкретных обучающих примеров. Другую стадию обучения, \textit{запоминание} (англ. memorization), напротив, выделяет заучивание объектов обучающей выборки. При обучении на реальных данных стадия запоминания сменяет стадию обобщения, что принято связывать с эффектом переобучения. Соответственно, при обучении со случайной разметкой весь процесс обучения представляет собой стадию запоминания.

Более поздние работы приводят другую интерпретацию описанного феномена. В одной из них \cite{frequency} было показано, что нейронные сети быстро выучивают низкочастотные компоненты целевой функции, а на высокочастотные компоненты уходит сравнительно больше времени обучения. Данное явление известно под названием \textit{спектральный сдвиг} (англ. spectral bias) \cite{spectralbias}. В указанной интерпретации низкочастотные компоненты соответствуют закономерностям в данных (стадия обобщения), а высокочастотные - шуму в данных (стадия запоминания). Кроме того, в последние годы появились теоретические свидетельства \cite{freqbias} спектрального сдвига, основанные на применении \textit{нейронного касательного ядра} (англ. Neural Tangent Kernel, NTK) \cite{ntk}, которое описывает динамику обучения полносвязной нейронной сети с бесконечной шириной.

Одна из недавних статей \cite{selfadaptive} показывает, что обобщение и запоминание у обучения с учителем и self-supervised learning методов устроены похожим образом. Авторы предлагают новый мета-алгоритм для обучения нейронных сетей, названный self-adaptive training. Он состоит в калибровке целевой переменной с учетом предсказаний модели. Согласно авторам, данный алгоритм применим и к задачам обучения с учителем, и к обучению в парадигме self-supervised learning. Он позволяет уменьшить зависимость моделей от шума в данных и повысить их обобщающую способность. Описанный результат связывает динамику обучения двух упомянутых постановок.

Наше исследование делает шаг в направлении изучения динамики обучения, эффектов обобщения и запоминания. При этом мы одновременно рассматриваем три постановки: парадигму self-supervised learning, обучение с учителем и обучение со случайной разметкой.
