На сегодняшний день огромное число задач, которые решаются с применением \textit{искусственных нейронных сетей} (англ. artificial neural networks), представляют собой задачи обучения с учителем. Фактически, это подразумевает выучивание нейронной сетью разметки, созданной человеком. В качестве примеров таких задач в компьютерном зрении можно привести классификацию изображений \cite{imagenet}, семантическую сегментацию \cite{cityscapes, pascalvoc}, детектирование объектов \cite{coco, pascalvoc}. Однако разметка данных --- это, как правило, длительный и дорогостоящий процесс, требующий привлечения человеческой экспертизы. Поэтому в последние несколько лет развиваются методы, позволяющие предобучать нейронные сети на неразмеченных данных. Данная парадигма известна под названием \textit{self-supervised learning}. Ее суть состоит в следующем: создать некоторую искусственную задачу, основанную на самих изображениях, и обучить нейронную сеть решать разработанную задачу. За последние годы появились работы, развивающие данную парадигму \cite{simclr, moco, byol, simsiam}. Актуальность темы подтверждается тем, что предобучение self-supervised learning методами показывает наилучшее качество на ряде контрольных задач, таких как семантическая сегментация и детектирование объектов. \blfootnote{Код экспериментов доступен по ссылке: {\url{https://github.com/isadrtdinov/self-supervised}}}.

Важное место в современном глубинном обучении занимает изучение обобщающей способности и динамики обучения нейронных сетей. Нейронные сети рассматриваются как универсальные аппроксиматоры, и, при наличии достаточного числа параметров, они могут приближать сколь угодно сложные функции, в том числе и случайный шум. Тем не менее, по предыдущим работам \cite{memorization, spectralbias, frequency} известно, что нейронные сети предпочитают выучивать простые закономерности быстрее, чем сложные. Обучение self-supervised learning методов радикально отличается от обучения с учителем, поскольку нет явного сопоставления обучающих объектов и целевых значений. Несмотря на это, мы показываем, что при обучении в парадигме self-supervised learning, как и при обучении с учителем, выделяются простые и сложные для выучивания нейронной сетью объекты. С другой стороны, между постановками существуют качественные различия: в частности, из наших экспериментов следует, что при обучении с учителем объекты имеют больший разброс сложности.

Также мы рассматриваем постановку с обучением нейронной сети на классификацию случайной разметки. Данная постановка представляет собой случай, когда нейронная сеть не имеет возможности выделять информативные закономерности, а потому вынуждена заучивать обучающие примеры. Мы приходим к выводу, что динамика обучения в парадигме self-supervised learning похожа на динамику обучения со случайной разметкой. Мы приводим эмпирическое подтверждение данного феномена и предлагаем интуицию, объясняющую наши наблюдения.
